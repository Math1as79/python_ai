{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My project part 1\n",
    "\n",
    "## Predict stock prices - Tesla!\n",
    "\n",
    "### Approach: \n",
    "    I want to look for breakout patterns in stocks in conjunction with sentiment analysis.\n",
    "    For breakout patterns I will use one approach with ML and one without. \n",
    "    For the tweets I will use natural language processing and use the clothing/book example as inspiration. \n",
    "\n",
    "### Data: \n",
    "    - Use Yahoo finance to get historical prices or download price history from kaggle.com\n",
    "    - Get stock tweets from www.kaggle.com \n",
    "        - One sentiment labeled dataset (general tweets) and one dataset containing non labeled tweets (Tesla tweets). The non labeled dataset will be decimated to only contain tweets concerning Tesla. \n",
    "    \n",
    "### Goal:\n",
    "    - I want to see if there is a connection between sentiment/buzz and the stock price, also if it has any affect on break out patterns.\n",
    "\n",
    "### Disclaimer: \n",
    "    Initial thought was to scrape X (twitter) for sentiment changes, but due to difficulties to extract that data I decided to go with a combination of already created datasets. \n",
    "    \n",
    "    The code below is just a initial cleaning of the dataset to be able to visualize the data in csv files in a more simple way. \n",
    "\n",
    "    The sentiment datasets doesn't have as much history as the stock price therefore it might be difficult to see any valid patterns for the stock I have investigated. I haven't yet decided of the periods I want to examine. The 5 years I have extraced below is made as a proof of concept. \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrive historical stock prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo webscraping example \n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "ticker = 'TSLA'\n",
    "\n",
    "tickers = yf.Tickers(ticker)\n",
    "df_prices = tickers.tickers[ticker].history(period=\"5y\")\n",
    "df_prices.to_csv(f'./data/prices/{ticker}_prices.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial cleaning of the none labeled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make non labeled dataset ready for sentiment analysis\n",
    "import re \n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    return ''.join(re.findall(r'[a-zA-Z0-9 ;+-:\"]', tweet))\n",
    "\n",
    "df_tweets = pd.read_csv('./data/sentiment/tweets_not_labeled.csv')\n",
    "\n",
    "df_nonlabeled_tweets = df_tweets.query(f\"StockName == '{ticker}'\", inplace=False)\n",
    "\n",
    "for i, row in df_nonlabeled_tweets.iterrows():\n",
    "    tweet = clean_tweet(df_nonlabeled_tweets.at[i, 'Tweet'])\n",
    "    df_nonlabeled_tweets.at[i, 'Tweet'] = str(tweet)\n",
    "\n",
    "df_nonlabeled_tweets = df_nonlabeled_tweets.drop(\"CompanyName\", axis='columns')\n",
    "df_nonlabeled_tweets = df_nonlabeled_tweets.rename(columns={'StockName': 'Ticker'})\n",
    "df_nonlabeled_tweets.to_csv(f'./data/sentiment/{ticker}_nonlabeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to clean the labeled tweets to be able to read it into a panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def validate_datetime(part):\n",
    "    try:\n",
    "        parse(part)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "        \n",
    "\n",
    "with open('./data/sentiment/tweets_labeled.csv', 'r', encoding=\"utf8\") as file_to_be_parsed:\n",
    "    file_content = file_to_be_parsed.read()\n",
    "\n",
    "values_to_be_removed = ['&amp;','&gt;',',','&lt;']\n",
    "\n",
    "# Replace values that causes issues with pandas read csv, don't want to drop bad lines. \n",
    "for value in values_to_be_removed:\n",
    "    file_content = file_content.replace(value,'')\n",
    "\n",
    "# Removing emojies, new lines, and other chars\n",
    "file_content = ''.join(re.findall(r'[a-zA-Z0-9 ;+-:\"]', file_content))\n",
    "\n",
    "parsed_file = []\n",
    "parts = file_content.split(';')\n",
    "\n",
    "for part in parts:\n",
    "    if part.isnumeric() == True:\n",
    "        parsed_file.append(part)\n",
    "    elif validate_datetime(part) == True:\n",
    "        parsed_file.append(part)\n",
    "    else:\n",
    "        # If the tweet contains the seperator char\n",
    "        if part.find('\"') == -1:\n",
    "            parsed_file.append(part)\n",
    "        else:\n",
    "            part = part.replace(';','')\n",
    "            parsed_file.append(part)\n",
    "\n",
    "# Creating a list of where the tweet should break\n",
    "row_breaks = ['sentiment','positive','neutral','negative']            \n",
    "\n",
    "#Need to put rowbreaks in again between the sentiment and the tweet id\n",
    "parsed_file_content = ','.join(parsed_file).split(',')\n",
    "parsed_file_linebreaks = []\n",
    "current_sentiment = ''\n",
    "for part in parsed_file_content:\n",
    "    found = False\n",
    "    for row_break in row_breaks:\n",
    "        if part.find(row_break) == -1:\n",
    "            found = False\n",
    "        else:\n",
    "            current_sentiment = row_break\n",
    "            found = True\n",
    "            break\n",
    "    \n",
    "    if found == True:\n",
    "        part_to_investigate = part[len(current_sentiment): ]\n",
    "        add_linebreak = False\n",
    "        for char in part_to_investigate:\n",
    "            if char.isnumeric() == False:\n",
    "                add_linebreak = False\n",
    "                break\n",
    "            else:\n",
    "                add_linebreak = True\n",
    "        \n",
    "        if add_linebreak == True:\n",
    "            parsed_file_linebreaks.append(current_sentiment + '\\n' + part_to_investigate) \n",
    "        else:\n",
    "            parsed_file_linebreaks.append(part)    \n",
    "    else:\n",
    "        parsed_file_linebreaks.append(part)\n",
    "\n",
    "with open('./data/sentiment/tweets_labeled_parsed.csv', 'w', encoding=\"utf8\") as file_parsed:\n",
    "    for row in parsed_file_linebreaks:\n",
    "        file_parsed.write(str(row + ','))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in cleaned file, make some modifications and save it with ticker name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_labeled_tweets = pd.read_csv('./data/sentiment/tweets_labeled_parsed.csv')\n",
    "\n",
    "df_labeled_tweets = df_labeled_tweets.rename(columns={'createdat': 'date', 'text': 'tweet'})\n",
    "df_labeled_tweets = df_labeled_tweets.assign(ticker=ticker)\n",
    "df_labeled_tweets.to_csv(f'./data/sentiment/{ticker}_labeled.csv')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
